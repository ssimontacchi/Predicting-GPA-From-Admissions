{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "style_table = open('/Users/Scott/Desktop/Data/style-table.css').read()\n",
    "style_notebook = open('/Users/Scott/Desktop/Data/style-notebook.css').read()\n",
    "css = style_table + style_notebook\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Best predictors of GPA success from a private school admissions profile using Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Admissions Data\n",
    "##### The first step was to take the admissions files and format them in Excel so that students who took the ISEE or SSAT entrance exams could be compared by looking at national percentile score. Also, admissions recommendations ratings shifted from a scale out of 4 to out of 5 over the years, so the scale needed to be standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines edited admissions files into a single dataframe with both ISEE and SSAT percentiles, retaining that info\n",
    "\n",
    "# Puts admissions data files into a list, reads them, and creates a dataframe\n",
    "counter = 4\n",
    "files = []\n",
    "\n",
    "for _ in range(5):\n",
    "    files.append('/Users/Scott/Desktop/Data/Admissions/0'+\n",
    "                 str(counter)+'_0'+str(counter+1)+'.xlsx')\n",
    "    counter += 1\n",
    "    \n",
    "for _ in range(1):\n",
    "    files.append('/Users/Scott/Desktop/Data/Admissions/0'+\n",
    "                 str(counter)+'_'+str(counter+1)+'.xlsx')\n",
    "    counter += 1\n",
    "    \n",
    "for _ in range(8):\n",
    "    files.append('/Users/Scott/Desktop/Data/Admissions/'+\n",
    "                 str(counter)+'_'+str(counter+1)+'.xlsx')\n",
    "    counter += 1\n",
    "    \n",
    "counter = 0\n",
    "for file in files:\n",
    "    files[counter] = pd.read_excel(file)\n",
    "    files[counter] = files[counter].dropna(axis=1, how=\"all\")\n",
    "    files[counter] = files[counter].dropna(axis=0, how=\"all\")\n",
    "    counter += 1\n",
    "\n",
    "# df_allstudents is a dataframe of all admissions data\n",
    "counter = 0\n",
    "df_allstudents = pd.DataFrame()\n",
    "for _ in range(len(files)):\n",
    "    df_allstudents = pd.concat([df_allstudents, files[counter]], sort=True)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolates certain columns to show cum. GPA, grades, testing, recommendation scores, sex, year of entry and exit, \n",
    "# grade applied to, financial aid, city, zip, has a sibling, has a parent who attended, and has a faculty parent.\n",
    "# create a copy to void SettingwithCopyWarning later on\n",
    "\n",
    "allstudents_cleaner = df_allstudents[['Cum','Eng_Rec_Rating','English_1','Ethnicity','FA_Request',\n",
    "                                      'FL_1','Grade_apply','History_1','Inquiry_source',\n",
    "                                      'Interview','Math','Math_1','Math_rec_rating',\n",
    "                                      'Princ_Rec_Rating','Quantitative','Reading',\n",
    "                                      'School_admprevious','Science_1','Sex','Test','Verbal',\n",
    "                                      'Writing','YOE','YOX','inq_FAM Family 1 [c]::P_city',\n",
    "                                      'isFacultyStudent', 'isLegacy', 'isSibling',\n",
    "                                      'NameLast']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no data, fill with 0 \n",
    "fillna_list = ['FA_Request','isFacultyStudent','isLegacy','isSibling','Inquiry_source']\n",
    "\n",
    "for col in fillna_list:\n",
    "    allstudents_cleaner[col] = allstudents_cleaner.loc[:, col].fillna(value=0)\n",
    "\n",
    "# replaces infrequent values with more general values\n",
    "changes = [('3+',2.78), ('A/A-','A'),('A+/A','A+'),('A-/B-','B+'),('C+/B+','B'),('C+/A /A-','A-'),\n",
    "           ('Multi-ethnic or Other (please describe)','Multi-Ethnic or Other'),\n",
    "           ('Multi-Ethnic or Other/AsAm','Multi-Ethnic or Other'),\n",
    "           ('Multi-Ethnic or Other/Asian, cauc','Multi-Ethnic or Other'),\n",
    "           ('Multi-EthKoreameri','Multi-Ethnic or Other'),\n",
    "           ('Multi-Eth As/Cauc','Multi-Ethnic or Other'),\n",
    "           ('Middle Eastern Americasian amer','Multi-Ethnic or Other'),\n",
    "           ('?','sf'),(44.00,4.00),('4-',3.06),('A-/sf','A-'),('Pass','sf')]\n",
    "for change in changes:\n",
    "    allstudents_cleaner = allstudents_cleaner.replace(change[0], change[1])\n",
    "    \n",
    "allstudents_cleaner = allstudents_cleaner[pd.notnull(allstudents_cleaner['YOX'])]\n",
    "\n",
    "# chooses the most common value for empty values for any empty values\n",
    "allstudents_cleaner = allstudents_cleaner.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Cleaning the GPA Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates ClassYear object that keeps the filename and year of exit (graduation) together\n",
    "class ClassYear:\n",
    "    def __init__(self, year):\n",
    "        year_abbrev = '\\'' + str(year)[2:]    # i.e. '08\n",
    "        self.filename = '/Users/Scott/Desktop/Data/Academics/Class of ' + year_abbrev + ' GPA.xls'\n",
    "        self.YOX = str(year-1) + \"-\" + str(year)\n",
    "    \n",
    "    def get_filename(self):\n",
    "        return self.filename\n",
    "    \n",
    "    def get_YOX(self):\n",
    "        return self.YOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts GPA data files into a list, reads them, and creates a dataframe of name, year of exit, and final GPA for merging\n",
    "\n",
    "class_years = [ClassYear(year) for year in range(2008, 2018)]\n",
    "    \n",
    "# df_allacademics is a dataframe of all admissions data, include year of exit (graduation) column\n",
    "\n",
    "df_allacademics = pd.DataFrame()\n",
    "df_allacademics['YOX'] = pd.Series()\n",
    "\n",
    "for grade in class_years:\n",
    "    df_allacademics = pd.concat([df_allacademics, pd.read_excel(grade.filename)], sort=True)\n",
    "    df_allacademics['YOX'] = df_allacademics['YOX'].fillna(value=grade.get_YOX())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates df of only name and GPA, sorted by name\n",
    "df_allacademics = df_allacademics[['NameLast',\n",
    "                                   'YOX','3-8']].dropna(axis=0, how=\"all\").sort_values(['NameLast'])\n",
    "df_allacademics.columns = ['NameLast','YOX','Grad_GPA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Merge Admissions and GPA data to prepare for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_with_GPA = pd.merge(allstudents_cleaner, df_allacademics, on=['NameLast','YOX'])\n",
    "admissions_with_GPA = admissions_with_GPA[admissions_with_GPA.Grad_GPA.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun finding: students who come in 6th graduate with higher GPAs than those who come in 9th\n",
    "\n",
    "sixes_or_nines = admissions_with_GPA.groupby(admissions_with_GPA.Grade_apply == 6).mean()\n",
    "sixes_or_nines = sixes_or_nines['Grad_GPA'].to_frame()\n",
    "sixes_or_nines = sixes_or_nines.rename({False: '9s', True: '6s'})\n",
    "sixes_or_nines.columns = ['Cumulative GPA']\n",
    "sixes_or_nines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "\n",
    "courses = ['Ethnicity','Inquiry_source','Sex','YOE','YOX','inq_FAM Family 1 [c]::P_city',\n",
    "        'English_1','FL_1','History_1','Math_1','Science_1','Test', 'School_admprevious']\n",
    "\n",
    "data_w_dummies = admissions_with_GPA.drop(['NameLast','Cum'], axis=1)\n",
    "\n",
    "counter = 0\n",
    "for col in courses:\n",
    "    foo = pd.get_dummies(data_w_dummies[col], prefix=col)\n",
    "    data_w_dummies = pd.concat([data_w_dummies.drop(col, axis=1), foo], axis=1, join='inner')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training and testing data\n",
    "\n",
    "# move Grad_GPA to end of the df for easy feature selection slicing\n",
    "data_w_dummies = data_w_dummies.reset_index().drop(['index'], axis=1).copy()\n",
    "cols = data_w_dummies.columns.tolist()\n",
    "cols.insert(len(cols)-1, cols.pop(cols.index('Grad_GPA')))\n",
    "df = data_w_dummies[cols].copy()\n",
    "\n",
    "sixes = df[df.Grade_apply==6].copy()\n",
    "nines = df[df.Grade_apply==9].copy()\n",
    "\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "\n",
    "sixes['is_train'] = np.random.uniform(0, 1, len(sixes)) <= .75\n",
    "nines['is_train'] = np.random.uniform(0, 1, len(nines)) <= .75\n",
    "\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "train_sixes, test_sixes = sixes[sixes['is_train']==True], sixes[sixes['is_train']==False]\n",
    "train_nines, test_nines = nines[nines['is_train']==True], nines[nines['is_train']==False]\n",
    "\n",
    "# features are everything but last two columns\n",
    "features = df.columns[:(len(df.columns)-2)]\n",
    "features_sixes = sixes.columns[:(len(sixes.columns)-2)]\n",
    "features_nines = nines.columns[:(len(nines.columns)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forests for all, sixes, and nines\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "sixes_rf = RandomForestRegressor()\n",
    "nines_rf = RandomForestRegressor()\n",
    "\n",
    "X = train[features]\n",
    "y = train['Grad_GPA']\n",
    "clf.fit(X,y)\n",
    "\n",
    "X_sixes = train_sixes[features_sixes]\n",
    "y_sixes = train_sixes['Grad_GPA']\n",
    "sixes_rf.fit(X_sixes,y_sixes)\n",
    "\n",
    "X_nines = train_nines[features_nines]\n",
    "y_nines = train_nines['Grad_GPA']\n",
    "nines_rf.fit(X_nines,y_nines)\n",
    "\n",
    "preds = clf.predict(test[features])\n",
    "results = pd.crosstab(test['Grad_GPA'], preds, rownames=['actual'], colnames=['preds'])\n",
    "\n",
    "preds_sixes = sixes_rf.predict(test_sixes[features_sixes])\n",
    "results_sixes = pd.crosstab(test_sixes['Grad_GPA'], preds_sixes, rownames=['actual'], colnames=['preds'])\n",
    "\n",
    "preds_nines = nines_rf.predict(test_nines[features_nines])\n",
    "results_nines = pd.crosstab(test_nines['Grad_GPA'], preds_nines, rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [10,20,30],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Grid_Search_CV_RFR(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_Search_CV_RFR(X_sixes,y_sixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid_Search_CV_RFR(X_nines,y_nines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression for whole dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "test_x = test[features]\n",
    "train_x = train[features]\n",
    "X = train_x\n",
    "y= train['Grad_GPA']\n",
    "\n",
    "\n",
    "estimator = RandomForestRegressor(n_jobs=-1).set_params(bootstrap=False, max_features='sqrt', \n",
    "                                                        min_samples_split=8, n_estimators=30)\n",
    "estimator.fit(X,y)\n",
    "\n",
    "GPA_reshape = test['Grad_GPA'].values\n",
    "\n",
    "print(\"R2 score:\", estimator.score(test_x, GPA_reshape))\n",
    "\n",
    "estimator.feature_importances_\n",
    "\n",
    "df_all = pd.DataFrame(estimator.feature_importances_, test_x.columns.values)\n",
    "df_all.columns = ['correlations']\n",
    "df_all = df_all.sort_values('correlations', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.round(3)\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[0:8].plot(kind='bar'); plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression for sixes\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "test_x_sixes= test_sixes[features_sixes]\n",
    "train_x_sixes= train_sixes[features_sixes]\n",
    "X = train_x_sixes\n",
    "y = train_sixes['Grad_GPA']\n",
    "\n",
    "\n",
    "estimator = RandomForestRegressor(n_jobs=-1).set_params(bootstrap=True, max_features='log2', \n",
    "                                                        min_samples_split=8, n_estimators=20)\n",
    "estimator.fit(X,y)\n",
    "\n",
    "cum_reshape = test_sixes['Grad_GPA'].values\n",
    "\n",
    "print (\"R2 score:\", estimator.score(test_x_sixes, cum_reshape))\n",
    "\n",
    "estimator.feature_importances_\n",
    "\n",
    "df_6 = pd.DataFrame(estimator.feature_importances_, test_x_sixes.columns.values)\n",
    "df_6.columns = ['correlations']\n",
    "df_6 = df_6.sort_values('correlations', ascending=False)\n",
    "df_6.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6[0:8].plot(kind='bar'); plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression for nines\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "test_x_nines= test_nines[features_nines]\n",
    "train_x_nines= train_nines[features_nines]\n",
    "X = train_x_nines\n",
    "y = train_nines['Grad_GPA']\n",
    "\n",
    "\n",
    "estimator = RandomForestRegressor(n_jobs=-1).set_params(bootstrap=False, max_features='sqrt', \n",
    "                                                        min_samples_split=8, n_estimators=20)\n",
    "estimator.fit(X,y)\n",
    "\n",
    "cum = test_nines['Grad_GPA'].values\n",
    "\n",
    "print (\"R2 score:\", estimator.score(test_x_nines, cum))\n",
    "\n",
    "estimator.feature_importances_\n",
    "\n",
    "df_9 = pd.DataFrame(estimator.feature_importances_, test_x_nines.columns.values)\n",
    "df_9.columns = ['correlations']\n",
    "df_9 = df_9.sort_values('correlations', ascending=False)\n",
    "df_9.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9[0:8].plot(kind='bar'); plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "#### While the r^2 shows that an admissions profile is quite a poor predictor of academic success, it is still interesting to see that 9th grade Reading standardized test scores are much more predictive of success than, say, math scores.\n",
    "#### Another interesting finding, below, is that while 9th graders have slightly higher admissions test scores, students who come in 6th grade graduate with higher GPAs, suggesting that the strong middle school education gives the students an advantage in high school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot changes over time by finding average \n",
    "df_tests = list(['Reading']+['Quantitative']+\n",
    "                      ['Verbal']+['Math'])\n",
    "tests = df.copy()[df_tests]\n",
    "tests['avg']= tests.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_sixes = list(['Reading']+['Quantitative']+\n",
    "                      ['Verbal']+['Math'])\n",
    "\n",
    "tests_sixes = sixes.copy()[df_tests_sixes]\n",
    "tests_sixes['avg6']= tests_sixes.mean(1)\n",
    "tests_sixes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_nines = list(['Reading']+['Quantitative']+\n",
    "                      ['Verbal']+['Math'])\n",
    "\n",
    "tests_nines = nines.copy()[df_tests_nines]\n",
    "tests_nines['avg9']= tests_nines.mean(1)\n",
    "tests_nines.describe()\n",
    "\n",
    "tests = pd.concat([tests_sixes['avg6'].to_frame(), tests_nines['avg9'].to_frame()], axis = 1)\n",
    "tests = tests.rename(index=str, columns={'avg6':'6th entrance tests','avg9':'9th entrance tests'})\n",
    "\n",
    "tests.boxplot()\n",
    "desc = tests.describe().drop((['count','mean', 'std', 'min']))\n",
    "desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixes_v_nines = pd.DataFrame({ '6s GPAs' : sixes['Grad_GPA'],'9s GPAs' : nines['Grad_GPA']})\n",
    "sixes_v_nines.boxplot()\n",
    "\n",
    "desc = sixes_v_nines.describe().drop((['count','mean', 'std', 'min', 'max']))\n",
    "desc.round(2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "b52022e4-adbb-45c5-967d-2125f5316c2b",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
